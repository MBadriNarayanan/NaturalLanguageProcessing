{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03StemmingAndLemmatization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPyMHxWfedN_",
        "colab_type": "text"
      },
      "source": [
        "# 1) Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30gNf6FTehj7",
        "colab_type": "text"
      },
      "source": [
        "Stemming works fairly well in most of the cases but unfortunately English has so many exceptions where a more sophisticated process is required\n",
        "\n",
        "**SpaCy dosen't include stemming**, it uses lemmatization instead"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMVPYv-XelBY",
        "colab_type": "text"
      },
      "source": [
        "Stemming is basically **removes the suffixes** from a word and reduce it to its root word.\n",
        "\n",
        "For example: “Flying” is a word and its suffix is “ing”, if we remove “ing” from “Flying” then we will get base word or root word which is “Fly”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrukMhO-epZc",
        "colab_type": "text"
      },
      "source": [
        "we will use Natural Language Toolkit (nltk) to understand and learn stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vjPn0FSevXk",
        "colab_type": "text"
      },
      "source": [
        "## Porter Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrqdDcBiOkFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciPn0oe8Sw8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_stemmer = PorterStemmer() # object of class PorterStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4rAQr6JTD8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = ['run','runner','running','ran','runs','easily','fairly'] # list of words "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qeravURTGtw",
        "colab_type": "code",
        "outputId": "5fc6ac15-2c06-418f-ad38-624318ef9746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "for word in words:\n",
        "  print(word + '------>' + p_stemmer.stem(word))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run------>run\n",
            "runner------>runner\n",
            "running------>run\n",
            "ran------>ran\n",
            "runs------>run\n",
            "easily------>easili\n",
            "fairly------>fairli\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ENSQal0T-ig",
        "colab_type": "text"
      },
      "source": [
        "## Snowball Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkkW6UEfT_yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Snowball Stemmer is also called the \"English Stemmer\" or \"Porter2 Stemmer\"\n",
        "# It offers a slight improvement over the original Porter stemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLsKD5GPUV-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "# Pass a language parameter\n",
        "s_stemmer = SnowballStemmer(language='english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sM8eeJcUWzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = ['run','runner','running','ran','runs','easily','fairly']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlCDR2PMUddi",
        "colab_type": "code",
        "outputId": "f598647b-b20f-41ed-9c12-0ee39cb68fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "for word in words:\n",
        "    print(word +' --> '+ s_stemmer.stem(word))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run --> run\n",
            "runner --> runner\n",
            "running --> run\n",
            "ran --> ran\n",
            "runs --> run\n",
            "easily --> easili\n",
            "fairly --> fair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSBalaQce-Lq",
        "colab_type": "text"
      },
      "source": [
        "# 2) Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8u9UdfpfFxI",
        "colab_type": "text"
      },
      "source": [
        "Lemmatization is **the Process of converting words into their dictionary form**\n",
        "\n",
        "Lemmatization considers full vocabulary of a language to apply a morphological analysis\n",
        "\n",
        "e.g.\n",
        "Word: Feet, Lemma: Foot\n",
        "\n",
        "**Stemming**\n",
        "It is the process of converting words into their non-changing portion\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldQsPORve_rH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCxEhTQdfA6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc1 = nlp(\"The striped bats are hanging on their feet for best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpXJ4g-wfCtl",
        "colab_type": "code",
        "outputId": "0661e478-09ef-4708-98a6-a3a1d84c8028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "for token in doc1:\n",
        "    print(token.text, '\\t', token.pos_, '\\t',token.lemma_)\n",
        "\n",
        "# token, POS, Lemma"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The \t DET \t the\n",
            "striped \t VERB \t stripe\n",
            "bats \t NOUN \t bat\n",
            "are \t AUX \t be\n",
            "hanging \t VERB \t hang\n",
            "on \t ADP \t on\n",
            "their \t DET \t -PRON-\n",
            "feet \t NOUN \t foot\n",
            "for \t ADP \t for\n",
            "best \t ADJ \t good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwkuzd_KgC_T",
        "colab_type": "text"
      },
      "source": [
        "# 3) Stemming vs Lemmaatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYDHaSgBgHZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc2 = ['the','striped','bats','are','hanging','on','their','feet','for','best']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcthufe0g_yC",
        "colab_type": "code",
        "outputId": "4df978e4-bd30-4a48-dd01-28528ddaed1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "for word in doc2:\n",
        "    print(word +' --> '+ s_stemmer.stem(word))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the --> the\n",
            "striped --> stripe\n",
            "bats --> bat\n",
            "are --> are\n",
            "hanging --> hang\n",
            "on --> on\n",
            "their --> their\n",
            "feet --> feet\n",
            "for --> for\n",
            "best --> best\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVQ87-tAiH1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lemma,      are ---> be\n",
        "# stemming,   are ---> are\n",
        "\n",
        "# lemma,      feet ---> foot\n",
        "# stemming,   feet ---> feet\n",
        "\n",
        "# lemma,      best ---> good\n",
        "# stemming,   best ---> best"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}